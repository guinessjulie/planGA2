## 생성형 모델 평가 지표 
이미지 합성 및 생성 모델을 평가하기 위해 사용되는 다른 주요 지표들은 다음과 같습니다:

1. FID : 생성된 이미지와 실제 이미지 간의 통계적 거리를 측정하여, 생성된 이미지가 실제 이미지와 얼마나 유사한지를 정량적으로 평가합니다. FID 점수는 다음과 같은 과정을 통해 계산됩니다:

3. **Inception Score (IS)**: Inception Score는 이미지의 질과 다양성을 동시에 평가하는 척도입니다. 이 지표는 Inception 모델을 사용하여 이미지를 분류하고, 분류 결과의 정보량을 기반으로 점수를 계산합니다. 높은 IS 값은 생성된 이미지가 높은 품질이며 다양하다는 것을 나타냅니다. 그러나 IS는 실제 데이터와의 직접적인 비교를 수행하지 않기 때문에, FID와 함께 사용될 때 더 유용합니다.
    
2. **Precision and Recall**: 생성된 이미지와 실제 이미지 사이의 정밀도(Precision)와 재현율(Recall)을 평가합니다. 정밀도는 생성된 이미지 중 실제 이미지와 유사한 이미지의 비율을, 재현율은 실제 이미지 집합을 얼마나 잘 커버하는지를 나타냅니다. 이 두 지표는 생성 모델이 실제 데이터 분포를 얼마나 잘 모사하는지를 다각도에서 평가합니다.
    
3. **Structural Similarity Index (SSIM)**: 두 이미지 간의 구조적 유사성을 측정하는 지표로, 밝기, 대비, 구조의 세 가지 측면을 고려합니다. SSIM은 특히 이미지 복원, 슈퍼 해상도와 같은 작업에서 선호되는 평가 척도입니다.
    
4. **Peak Signal-to-Noise Ratio (PSNR)**: 이미지 간의 차이를 픽셀 단위의 오차로 측정하여 신호 대 잡음 비율을 계산합니다. PSNR은 이미지 복원이나 압축에서 널리 사용되는 지표이지만, 인간의 시각적 인식과 완벽하게 일치하지 않는다는 한계가 있습니다.
    
5. **Learned Perceptual Image Patch Similarity (LPIPS)**: 딥러닝을 기반으로 한 지표로, 인간의 지각에 기반하여 두 이미지 간의 유사성을 측정합니다. 이는 전통적인 픽셀 기반 접근법보다 인간의 시각적 판단과 더 일치하는 결과를 제공합니다.
    
6. **Mode Score**: Inception Score의 변형으로, 생성된 이미지의 품질과 다양성을 평가하는 동시에, 생성된 이미지가 실제 데이터의 모드(유니크한 특성이나 카테고리)를 얼마나 잘 포착하는지를 추가적으로 평가합니다.
    

이러한 지표들은 각기 다른 측면을 평가하며, 특정 작업이나 목적에 따라 적절한 지표를 선택하여 사용하는 것이 중요합니다. 생성된 이미지의 품질, 다양성, 실제성, 그리고 구조적 유사성 등을 종합적으로 고려할 때, 더 포괄적이고 정확한 모델 평가가 가능해집니다.
## FID
FID(Fréchet Inception Distance) 점수는 생성된 이미지의 품질을 평가하는 데 널리 사용되는 척도입니다. 이 지표는 생성된 이미지와 실제 이미지 간의 통계적 거리를 측정하여, 생성된 이미지가 실제 이미지와 얼마나 유사한지를 정량적으로 평가합니다. FID 점수는 다음과 같은 과정을 통해 계산됩니다:

1. **특성 추출**: 먼저, Inception v3 네트워크와 같은 사전 훈련된 딥러닝 모델을 사용하여, 생성된 이미지와 실제 이미지 모두에서 특성을 추출합니다. 이 단계에서는 이미지에서 고수준의 특성을 추출하여, 이미지의 본질적인 시각적 특성을 나타내는 벡터를 생성합니다.

2. **통계적 분석**: 추출된 특성을 기반으로, 각 이미지 집합(생성된 이미지와 실제 이미지)의 평균과 공분산을 계산합니다. 이 통계적 분석은 이미지 집합이 갖는 시각적 특성의 분포를 나타냅니다.

3. **거리 계산**: 마지막으로, 생성된 이미지 집합과 실제 이미지 집합 간의 평균과 공분산을 사용하여, 두 집합 사이의 Fréchet 거리(또는 Wasserstein-2 거리)를 계산합니다. 이 거리는 두 확률 분포 간의 차이를 나타내며, FID 점수로 사용됩니다.

FID 점수는 두 가지 주요 측면을 평가합니다:

- **질적 측면**: 생성된 이미지가 실제로 얼마나 질적으로 우수한가를 평가합니다. 점수가 낮을수록 생성된 이미지의 품질이 높다고 간주됩니다.
- **다양성**: 생성된 이미지 집합이 실제 이미지 집합의 다양성을 얼마나 잘 반영하는지를 평가합니다. 생성된 이미지가 실제 이미지와 유사한 다양한 패턴과 특성을 가지고 있다면, FID 점수는 낮아집니다.

결과적으로, 낮은 FID 점수는 생성된 이미지가 실제 이미지와 유사한 고품질의 다양성을 가지고 있음을 나타내며, 이미지 생성 모델의 성능을 평가하는 데 중요한 척도로 사용됩니다.

## FID 평가 방법
FID(Fréchet Inception Distance)는 생성된 이미지와 실제 이미지 간의 거리를 측정하는 데 사용되는 수학적 방법으로, 두 이미지 세트 간의 통계적 차이를 기반으로 합니다. FID의 계산은 다음과 같은 단계로 이루어집니다:

1. **특성 추출**: 먼저, Inception 모델과 같은 사전 훈련된 딥러닝 모델을 사용하여, 생성된 이미지 세트와 실제 이미지 세트 모두에서 특성 벡터를 추출합니다. 이 특성 벡터는 이미지의 중요한 시각적 정보를 캡처합니다.

2. **통계 계산**: 각 이미지 세트에서 추출된 특성 벡터들의 평균 $\mu$과 공분산($\Sigma$)을 계산합니다. 이때, 생성된 이미지 세트의 평균과 공분산을 ($\mu_g, \Sigma_g$), 실제 이미지 세트의 평균과 공분산을 ($\mu_r, \Sigma_r$)로 표기합니다.

3. **Fréchet 거리 계산**: 생성된 이미지 세트와 실제 이미지 세트 간의 거리는 Fréchet 거리(또는 Wasserstein-2 거리)를 사용하여 계산합니다. 이 거리는 다음 공식으로 주어집니다:
$$ FID = ||\mu_g - \mu_r||^2_2 + Tr(\Sigma_g + \Sigma_r - 2(\Sigma_g\Sigma_r)^{1/2}) $$
여기서, $(||\mu_g - \mu_r||^2_2$)는 두 평균 벡터 간의 유클리드 거리의 제곱을 나타내며, $(Tr(\cdot)$)는 행렬의 트레이스(대각합)를 의미합니다. $((\Sigma_g\Sigma_r)^{1/2}$)는 두 공분산 행렬의 곱의 제곱근을 나타내며, 이는 공분산 행렬의 곱에 대한 행렬 제곱근을 계산하는 것을 의미합니다.

FID 점수는 두 이미지 세트 간의 통계적 차이를 나타내며, 점수가 낮을수록 생성된 이미지가 실제 이미지와 유사하다는 것을 의미합니다. FID는 이미지의 질뿐만 아니라 다양성도 함께 고려하기 때문에, 이미지 생성 모델의 성능을 평가하는 데 널리 사용됩니다.

### IS 평가방법
Inception Score (IS)는 생성된 이미지의 품질을 평가하는 척도로, 이미지가 얼마나 다양하면서도 각 이미지가 명확하게 어떤 클래스에 속하는지를 동시에 측정합니다. IS는 다음 단계를 통해 계산됩니다:

1. **클래스 분류 확률의 계산**: 생성된 각 이미지에 대해, 사전 훈련된 분류 모델(Inception 모델이 일반적으로 사용됨)을 사용하여 이미지가 각 클래스에 속할 확률을 계산합니다. 각 이미지 \(i\)에 대해, 모델은 클래스 \(j\)에 속할 확률 \(P(y_j|x_i)\)을 출력합니다.

2. **각 이미지의 조건부 분포의 엔트로피 계산**: 각 생성된 이미지에 대해 조건부 분포 \(P(y|x)\)의 엔트로피를 계산합니다. 이는 이미지가 얼마나 명확하게 특정 클래스에 속하는지를 나타냅니다. 낮은 엔트로피는 이미지가 명확한 클래스를 가지며, 높은 확신으로 분류됨을 의미합니다.

   $$H(y|x) = -\sum_j P(y_j|x) \log P(y_j|x) $$

3. **이미지 집합의 마지널 분포 엔트로피 계산**: 생성된 모든 이미지에 대한 클래스의 마지널 분포 $(P(y)$)를 계산하고, 이 분포의 엔트로피를 계산합니다. 마지널 분포는 각 클래스에 대해 모든 이미지에 걸쳐 클래스 확률을 평균한 것입니다. 이 엔트로피는 생성된 이미지 집합의 다양성을 나타냅니다. 다양성이 높을수록 엔트로피가 높아집니다.

   $$ H(y) = -\sum_j P(y_j) \log P(y_j) $$

   여기서, $(P(y_j) = \frac{1}{N} \sum_i P(y_j|x_i)$)는 모든 생성된 이미지에 대한 클래스 $(j$)의 평균 확률입니다.

4. **Inception Score 계산**: 최종적으로, IS는 모든 생성된 이미지에 대한 조건부 분포 엔트로피의 평균과 마지널 분포 엔트로피의 차이를 지수 함수로 취한 값으로 계산됩니다. 이는 다음과 같이 표현됩니다:

   $$ IS = \exp\left( E_x[H(y) - H(y|x)] \right) $$

   여기서, $(E_x[\cdot]$)는 생성된 모든 이미지에 대한 기대값을 나타냅니다.

IS는 높을수록 좋으며, 생성된 이미지가 명확하게 분류될 수 있고(높은 확신), 동시에 다양한 클래스의 이미지를 생성한다는 것을 의미합니다. 그러나 IS는 실제 이미지와의 비교 없이 생성된 이미지만을 기반으로 계산되기 때문에, FID와 같은 다른 지표와 함께 사용될 때 더 유익한 정보를 제공합니다.

Precision과 Recall은 생성된 이미지의 품질과 다양성을 평가하는 데 사용되는 두 가지 중요한 척도입니다. 이들은 특히 생성 모델이 실제 데이터 분포를 얼마나 잘 모사하는지를 평가하는 데 유용합니다. 여기서 Precision은 생성된 이미지 중 실제와 유사한 이미지의 비율을 나타내고, Recall은 실제 이미지 분포를 생성 모델이 얼마나 잘 커버하는지를 나타냅니다.

### Precision과 Recall 계산 방법

1. **특성 추출**:
   - 먼저, 생성된 이미지와 실제 이미지 모두에서 특성을 추출하기 위해 사전 훈련된 딥러닝 모델(예: Inception 모델)을 사용합니다.
   - 이러한 특성은 이미지의 시각적 내용을 요약하여, 이미지 간의 비교를 가능하게 합니다.

2. **가까운 이웃 찾기**:
   - 추출된 특성을 사용하여, 생성된 각 이미지에 대해 실제 이미지 특성들 중 가장 가까운 이웃을 찾습니다.
   - 마찬가지로, 실제 각 이미지에 대해서도 생성된 이미지 특성들 중 가장 가까운 이웃을 찾습니다.

3. **Precision 계산**:
   - Precision은 생성된 이미지들 중 실제 이미지와 유사한 이미지들의 비율로 계산됩니다.
   - 이는 생성된 이미지가 실제 데이터 분포에 얼마나 "정확하게" 맞는지를 나타냅니다.
   - 구체적으로, 생성된 이미지의 특성과 가장 가까운 실제 이미지 특성 간의 거리가 특정 임계값 이하인 경우, 그 이미지를 정확한 것으로 간주합니다.

4. **Recall 계산**:
   - Recall은 실제 이미지 분포가 생성된 이미지에 의해 얼마나 잘 "재현"되는지를 나타냅니다.
   - 실제 이미지의 특성과 가장 가까운 생성된 이미지 특성 간의 거리가 특정 임계값 이하인 경우, 해당 실제 이미지가 잘 커버된 것으로 간주합니다.
   - Recall은 이러한 방식으로 커버된 실제 이미지의 비율로 계산됩니다.

### 평가 기준

- **높은 Precision**: 생성 모델이 실제와 매우 유사한 고품질의 이미지를 생성한다는 것을 의미합니다. 그러나 다양성이 부족할 수 있습니다.
- **높은 Recall**: 생성 모델이 실제 이미지 분포의 다양한 부분을 잘 커버한다는 것을 의미합니다. 그러나 품질이 낮을 수 있습니다.

Precision과 Recall은 서로 trade-off 관계에 있을 수 있으며, 이상적인 생성 모델은 두 척도 모두에서 높은 성능을 보여야 합니다. 이러한 척도들을 사용함으로써, 연구자들은 생성 모델의 성능을 더 정확하게 평가하고, 모델 개선 방향을 결정할 수 있습니다.

둘 다 분포에 대한 이진 집합 구성원의 기대치로 계산됩니다. 즉, 한 분포에서 가져온 이미지가 다른 분포의 지원에 속하는 것으로 분류될 가능성을 측정하여 계산됩니다. 대조적으로, Sajjadi et al. [25] 두 분포의 상대 확률 밀도를 통해 정밀도와 재현율을 공식화합니다. 상대 밀도를 모델링하는 선택은 모호함에서 비롯됩니다. 즉, 두 분포 사이의 차이가 실제 분포를 부적절하게 포함하는 생성기 때문인지 또는 비현실적인 샘플을 생성하는 생성기 때문인지 여부입니다. 저자는 극한값이 고전적인 정의에 해당하는 정밀도/재현율 값의 연속체를 모델링하여 이러한 모호성을 해결합니다. 어떤 값을 사용할 것인지에 대한 질문을 제기하는 것 외에도 실제 알고리즘은 상대 밀도에 의존하기 때문에 극한값을 안정적으로 추정할 수 없습니다. 예를 들어 많은 수의 샘플이 함께 압축되는 상황을 올바르게 해석할 수 없습니다. 모드 축소 또는 잘림의 결과입니다. Lopez-Paz et.의 k-최근접 이웃 기반 2-표본 검정. 알. [17] 같은 문제를 겪고 있다. 우리 연구와 병행하여 Simon et al. [27] Sajjadi의 공식을 임의의 확률 분포로 확장하고 사후 분류기를 훈련하여 정밀도와 재현율을 추정하는 실용적인 알고리즘을 제공합니다.

이진 함수 \( f(\phi, \Phi) \)는 주어진 샘플 \( \phi \)와 특성 벡터 집합 \( \Phi \)에 대해 정의됩니다. 이 함수는 다음과 같이 작동합니다:

- \( f(\phi, \Phi) = 1 \), 만약 \( ||\phi - \phi'||_2 \leq ||\phi' - NN_k(\phi', \Phi)||_2 \) 를 만족하는 적어도 하나의 \( \phi' \in \Phi \)가 있을 경우. 여기서 \( ||\cdot||_2 \)는 유클리드 노름(유클리드 거리)를 나타내고, \( NN_k(\phi', \Phi) \)는 \( \phi' \)의 \( k \)-번째 가장 가까운 이웃을 \( \Phi \) 내에서 찾는 함수입니다.
- \( f(\phi, \Phi) = 0 \), 그 외의 경우.

간단히 말해서, 이 함수는 특정 샘플 \( \phi \)가 정의된 초구 내에 위치하는지를 결정합니다. 만약 \( \phi \)가 \( \Phi \) 집합 내의 어떤 특성 벡터 \( \phi' \)의 \( k \)번째 가장 가까운 이웃과의 거리 안에 있다면, \( \phi \)는 해당 초구 내에 있다고 간주되며, 이 함수는 1을 출력합니다. 그렇지 않으면 0을 출력합니다. 이것은 생성된 샘플이 특성 공간에서 어떻게 분포하는지를 이해하는 데 도움이 될 수 있습니다.

